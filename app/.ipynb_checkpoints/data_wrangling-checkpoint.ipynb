{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/01/05 14:29:22 WARN Utils: Your hostname, tai-XPS-13-9350 resolves to a loopback address: 127.0.1.1; using 172.17.0.1 instead (on interface docker0)\n",
      "22/01/05 14:29:22 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/home/tai/Desktop/Projects/springboard_final/app/env/lib/python3.8/site-packages/pyspark/jars/spark-unsafe_2.12-3.2.0.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/01/05 14:29:23 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "/home/tai/Desktop/Projects/springboard_final/app/env/lib/python3.8/site-packages/pyspark/sql/context.py:77: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://172.17.0.1:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.2.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fb9bbbc49d0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyspark\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "if 'sc' not in locals():\n",
    "    from pyspark.context import SparkContext\n",
    "    from pyspark.sql.context import SQLContext\n",
    "    from pyspark.sql.session import SparkSession\n",
    "    \n",
    "    sc = SparkContext()\n",
    "    sqlContext = SQLContext(sc)\n",
    "    spark = SparkSession(sc)\n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(glob.glob(\"data/NBA*\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mypath = './data'\n",
    "files =  glob.glob(\"data/NBA*\")\n",
    "\n",
    "\n",
    "for file in files:\n",
    "    df = pd.read_csv(file)\n",
    "    if \"Unnamed: 40\" in df.columns:\n",
    "        df = df.drop([\"Unnamed: 40\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "\n",
    "# Auxiliar functions\n",
    "def equivalent_type(f):\n",
    "    if f == 'datetime64[ns]': return TimestampType()\n",
    "    elif f == 'int64': return LongType()\n",
    "    elif f == 'int32': return IntegerType()\n",
    "    elif f == 'float64': return FloatType()\n",
    "    else: return StringType()\n",
    "\n",
    "def define_structure(string, format_type):\n",
    "    try: typo = equivalent_type(format_type)\n",
    "    except: typo = StringType()\n",
    "    return StructField(string, typo)\n",
    "\n",
    "# Given pandas dataframe, it will return a spark's dataframe.\n",
    "def pandas_to_spark(pandas_df):\n",
    "    columns = list(pandas_df.columns)\n",
    "    types = list(pandas_df.dtypes)\n",
    "    struct_list = []\n",
    "    for column, typo in zip(columns, types): \n",
    "      struct_list.append(define_structure(column, typo))\n",
    "    p_schema = StructType(struct_list)\n",
    "    return sqlContext.createDataFrame(pandas_df, p_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "mypath = './data'\n",
    "files =  glob.glob(\"data/NBA*\")\n",
    "\n",
    "spark_table_games = \"games\"\n",
    "for file in files:\n",
    "    df = pd.read_csv(file)\n",
    "    if \"Unnamed: 40\" in df.columns:\n",
    "        df = df.drop([\"Unnamed: 40\"], axis=1)\n",
    "    sparkDF=spark.createDataFrame(df) \n",
    "    sparkDF.write.format(\"parquet\").saveAsTable(spark_table_games, mode='append')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(f\"drop table games\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(spark_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "csv_files = glob.glob(\"data/NBA*\")\n",
    "\n",
    "file_type = \"csv\"\n",
    "\n",
    "# CSV options\n",
    "infer_schema = \"true\"\n",
    "first_row_is_header = \"true\"\n",
    "delimiter = \",\"\n",
    "\n",
    "# The applied options are for CSV files. For other file types, these will be ignored.\n",
    "df_games = (spark.read.format(file_type) \n",
    "                    .option(\"inferSchema\", infer_schema) \n",
    "                    .option(\"header\", first_row_is_header) \n",
    "                    .option(\"sep\", delimiter) \n",
    "                    .load(csv_files))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- URL: string (nullable = true)\n",
      " |-- GameType: string (nullable = true)\n",
      " |-- Location: string (nullable = true)\n",
      " |-- Date: string (nullable = true)\n",
      " |-- Time: string (nullable = true)\n",
      " |-- WinningTeam: string (nullable = true)\n",
      " |-- Quarter: string (nullable = true)\n",
      " |-- SecLeft: string (nullable = true)\n",
      " |-- AwayTeam: string (nullable = true)\n",
      " |-- AwayPlay: string (nullable = true)\n",
      " |-- AwayScore: string (nullable = true)\n",
      " |-- HomeTeam: string (nullable = true)\n",
      " |-- HomePlay: string (nullable = true)\n",
      " |-- HomeScore: string (nullable = true)\n",
      " |-- Shooter: string (nullable = true)\n",
      " |-- ShotType: string (nullable = true)\n",
      " |-- ShotOutcome: string (nullable = true)\n",
      " |-- ShotDist: string (nullable = true)\n",
      " |-- Assister: string (nullable = true)\n",
      " |-- Blocker: string (nullable = true)\n",
      " |-- FoulType: string (nullable = true)\n",
      " |-- Fouler: string (nullable = true)\n",
      " |-- Fouled: string (nullable = true)\n",
      " |-- Rebounder: string (nullable = true)\n",
      " |-- ReboundType: string (nullable = true)\n",
      " |-- ViolationPlayer: string (nullable = true)\n",
      " |-- ViolationType: string (nullable = true)\n",
      " |-- TimeoutTeam: string (nullable = true)\n",
      " |-- FreeThrowShooter: string (nullable = true)\n",
      " |-- FreeThrowOutcome: string (nullable = true)\n",
      " |-- FreeThrowNum: string (nullable = true)\n",
      " |-- EnterGame: string (nullable = true)\n",
      " |-- LeaveGame: string (nullable = true)\n",
      " |-- TurnoverPlayer: string (nullable = true)\n",
      " |-- TurnoverType: string (nullable = true)\n",
      " |-- TurnoverCause: string (nullable = true)\n",
      " |-- TurnoverCauser: string (nullable = true)\n",
      " |-- JumpballAwayPlayer: string (nullable = true)\n",
      " |-- JumpballHomePlayer: string (nullable = true)\n",
      " |-- JumpballPoss: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_games.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/01/05 14:30:25 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "22/01/05 14:30:37 WARN CSVHeaderChecker: Number of column in CSV header is not equal to number of fields in the schema:\n",
      " Header length: 41, schema size: 40\n",
      "CSV file: file:///home/tai/Desktop/Projects/springboard_final/app/data/NBA_PBP_2019-20.csv\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# create table\n",
    "spark_table_games = \"games\"\n",
    "df_games.write.format(\"parquet\").saveAsTable(spark_table_games)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(count(1)=3040524)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/01/05 15:09:48 WARN HeartbeatReceiver: Removing executor driver with no recent heartbeats: 262387 ms exceeds timeout 120000 ms\n",
      "22/01/05 15:09:48 WARN SparkContext: Killing executors is not supported by current scheduler.\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT count(*) from games\").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################\n",
    "# Using database below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from databaseClass import DB\n",
    "import utils\n",
    "import sql_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "userName = utils.userName\n",
    "userPass = utils.userPass\n",
    "dbName = utils.dbName\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = DB(userName = userName, userPass = userPass, dataBaseName = dbName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "fd = open('sql_files/shot_performance.sql', 'r')\n",
    "sqlFile = fd.read()\n",
    "fd.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('sql_files/shot_performance.sql', 'r') as file: # Use file to refer to the file object\n",
    "    sql = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_file = open('sql_files/shot_performance.sql')\n",
    "sql_as_string = sql_file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"\"\"\n",
    "select\n",
    "url,\n",
    "gametype,\n",
    "date,\n",
    "shooter,\n",
    "sum(case when shottype like '%%2-pt%%' and shotoutcome='make' then 1 else 0 end) as two_point_shots_made,\n",
    "count(*) as total_shots\n",
    "from public.pbp\n",
    "group by 1,2,3,4\n",
    "limit 10\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = '''\n",
    "\n",
    "select * from public.pbp limit 10\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(case when shottype like '%%2-pt%%' and shotoutcome='make' then 1 else 0 end) as two_point_shots_made,\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>gametype</th>\n",
       "      <th>date</th>\n",
       "      <th>shooter</th>\n",
       "      <th>two_point_shots_made</th>\n",
       "      <th>total_shots</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/boxscores/201510270ATL.html</td>\n",
       "      <td>regular</td>\n",
       "      <td>October 27 2015</td>\n",
       "      <td>A. Baynes - baynear01</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/boxscores/201510270ATL.html</td>\n",
       "      <td>regular</td>\n",
       "      <td>October 27 2015</td>\n",
       "      <td>A. Drummond - drumman01</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/boxscores/201510270ATL.html</td>\n",
       "      <td>regular</td>\n",
       "      <td>October 27 2015</td>\n",
       "      <td>A. Horford - horfoal01</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/boxscores/201510270ATL.html</td>\n",
       "      <td>regular</td>\n",
       "      <td>October 27 2015</td>\n",
       "      <td>D. Schröder - schrode01</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/boxscores/201510270ATL.html</td>\n",
       "      <td>regular</td>\n",
       "      <td>October 27 2015</td>\n",
       "      <td>E. İlyasova - ilyaser01</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>/boxscores/201510270ATL.html</td>\n",
       "      <td>regular</td>\n",
       "      <td>October 27 2015</td>\n",
       "      <td>J. Meeks - meeksjo01</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>/boxscores/201510270ATL.html</td>\n",
       "      <td>regular</td>\n",
       "      <td>October 27 2015</td>\n",
       "      <td>J. Teague - teaguje01</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>/boxscores/201510270ATL.html</td>\n",
       "      <td>regular</td>\n",
       "      <td>October 27 2015</td>\n",
       "      <td>K. Bazemore - bazemke01</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>/boxscores/201510270ATL.html</td>\n",
       "      <td>regular</td>\n",
       "      <td>October 27 2015</td>\n",
       "      <td>K. Caldwell-Pope - caldwke01</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>/boxscores/201510270ATL.html</td>\n",
       "      <td>regular</td>\n",
       "      <td>October 27 2015</td>\n",
       "      <td>K. Korver - korveky01</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            url gametype             date  \\\n",
       "0  /boxscores/201510270ATL.html  regular  October 27 2015   \n",
       "1  /boxscores/201510270ATL.html  regular  October 27 2015   \n",
       "2  /boxscores/201510270ATL.html  regular  October 27 2015   \n",
       "3  /boxscores/201510270ATL.html  regular  October 27 2015   \n",
       "4  /boxscores/201510270ATL.html  regular  October 27 2015   \n",
       "5  /boxscores/201510270ATL.html  regular  October 27 2015   \n",
       "6  /boxscores/201510270ATL.html  regular  October 27 2015   \n",
       "7  /boxscores/201510270ATL.html  regular  October 27 2015   \n",
       "8  /boxscores/201510270ATL.html  regular  October 27 2015   \n",
       "9  /boxscores/201510270ATL.html  regular  October 27 2015   \n",
       "\n",
       "                        shooter  two_point_shots_made  total_shots  \n",
       "0         A. Baynes - baynear01                     3            5  \n",
       "1       A. Drummond - drumman01                     6           16  \n",
       "2        A. Horford - horfoal01                     5           11  \n",
       "3       D. Schröder - schrode01                     6           14  \n",
       "4       E. İlyasova - ilyaser01                     3           12  \n",
       "5          J. Meeks - meeksjo01                     1            4  \n",
       "6         J. Teague - teaguje01                     6           16  \n",
       "7       K. Bazemore - bazemke01                     0            3  \n",
       "8  K. Caldwell-Pope - caldwke01                     3           14  \n",
       "9         K. Korver - korveky01                     2            9  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.DBtoDF(sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "springboard_final2",
   "language": "python",
   "name": "springboard_final2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
